---
layout:     post
title:      "FloNa 论文研读"
subtitle:   "FloNa: Floor Plan Guided Embodied Visual Navigation 论文研读"
date:       2025-06-22 20:00:00
author:     "hyy"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - FPN
---

本文提出了**Floor Plan Visual Navigation（平面图视觉导航，FloNa）** 任务，让智能体利用楼层平面图和 RGB 观测值导航至目标位置，旨在解决现有视觉导航未利用平面图先验知识的问题。为此，作者设计了 **FloDiff 扩散策略框架**，通过定位模块对齐观测与平面图，并收集了 iGibson 模拟器中 117 个场景的 20k 导航 episodes 构成数据集。实验表明，FloDiff 在陌生场景中成功率（SR）和路径效率（SPL）优于基线方法，且在 AGV 上的真实部署验证了其鲁棒性

1. 处理平面图与实际场景布局之间的空间不一致性，以实现无碰撞导航：扩散策略，通过大量演示数据学习在复杂场景中的导航能力
2. 将观测图像与平面图纸草图进行跨模态对齐：从观测中显式预测智能体位姿，或利用预训练模型进行位姿预测

## 部分名词解释

- 自动导引车（AGV）

  无需人工驾驶，能在预设环境中自动导航（按预设路径或实时规划的路线移动）的轮式移动机器人

- 端到端（end）

  指模型从原始输入到最终输出的全流程无需人工干预或分阶段处理，直接学习输入与输出之间的映射关系

  数据驱动，自动学习全流程的最优映射，避免中间环节误差累积

- A * 算法：启发式图搜索算法，通过结合**实际代价**和**启发式估计代价**来高效找到从起点到目标的最优路径

  - 在每一步扩展节点时，会计算每个候选节点的**总成本估计值**，选择估计值最小的节点优先扩展，直至找到目标节点

    $f(n)=g(n)+h(n)$

    - $f(n)$：节点 n 的总成本估计值
    - $g(n)$：从起点到节点 n 的实际代价（如移动距离、时间）
    - $h(n)$：从节点 n 到目标的启发式估计代价（需满足**可采纳性**，即不高估实际代价）

  引入启发式函数 $h(n)$ 的核心目的是**引导搜索方向，提高路径规划的效率**

  - 减少大量冗余的计算，算法优先扩展 “更可能接近目标” 的节点，大幅减少搜索空间（“导航指南针”的效果）

- 扩散模型：一种用于生成任务的概率框架

  通过迭代去噪过程学习逐步对采样的高斯噪声进行去噪，以生成所需数据

- 扩散策略：将通常用于内容生成的扩散模型概念扩展到策略学习中，使智能体能够基于学习的概率分布做出决策

  包含一个编码器，用于将观测转换为低维特征，作为去噪过程的条件

- 导航片段（导航“Episode”）

  1. **随机选定的起点** 和 **目标点**
  2. 从起点到目标点的**最短路径或采样路径**，以及沿途的**视觉观测序列**
  3. 对应的**动作序列**（如前进、转向等）

## 引入

任务：具身智能体在 3D 环境中从起始位置导航至特定目标位置（多样化环境：点、图像、物体、语言指令）

仅能接收：

- 以自我为中心的 RGB 图像
- 环境的楼层平面图图像
- 目标位置

> 实验采用 Locobot 作为具身智能体（高度 0.85 米，底座半径 0.18 米，分辨率为 512×512 像素的 RGB 摄像头）

---

现有：利用先验知识提高效率和准确性（楼层平面图）

- 依赖多传感器融合
- 对楼层平面图结构施加约束

限制了实际适用性

---

人类高效导航能力：利用最少抽象信息和视觉线索

FloNa：智能体利用抽象的楼层平面图和一系列 RGB 观测值在环境中进行导航

挑战：

- 楼层平面图与实际观测到的布局存在显著差异，导致空间不一致问题

  这种不一致可能在导航过程中引发**碰撞**	

- 由于楼层平面图提供的是抽象的拓扑信息，而 RGB 观测值捕捉的是特定视角下自然场景的外观，从而产生观测错位问题

  这种错位会导致当前观测值在楼层平面图中的**定位错误**，进而影响规划的有效性

---

FloDiff：端到端的扩散策略框架，解决 FloNa 任务

- 利用强大的动作分布建模能力，通过大量演示隐式学习处理空间不一致问题

- 集成了显式定位模块以对齐观测与平面图，根据智能体当前位姿的推导方式形成两种变体

  1. NaiveFloDiff，在训练过程中学习预测位姿
  2. Loc-FloDiff，直接使用真实位姿或预训练模型的预测结果

  将融合特征输入策略网络，以学习对动作序列进行去噪

定位、避障、多样化目标规划和鲁棒性

## 研究现状

### 视觉导航

机器人或自主智能体能够利用视觉信息在环境中导航

- 智能体导航到特定位置，强调自我定位能力
  - 点目标
- 涉及环境的常识性知识，例如识别物体并理解它们的常见位置
  - 物体目标
  - 区域目标
- 由高级语义引导的导航任务
  - 图像导航
  - 语言导航

未知环境的任务？

### 用于定位和导航的楼层平面图

<img src="/img/FPN/FloNa/floor-plan.png" alt="floor-plan" style="zoom:50%;" />

- 将楼层平面图与激光雷达、图像或视觉里程计等多种传感器信号结合使用
- 基于学习的方法
- 使用从草绘楼层平面图或建筑楼层平面图生成的增强拓扑图来辅助导航

## 方法

![method](/img/FPN/FloNa/method.png)

- 采用注意力模块融合视觉观测和楼层平面图的特征，生成上下文嵌入 $c_t$
- 根据智能体当前位姿的推导方式
  - NaiveFloDiff：在策略学习过程中学习预测当前位姿
  - Loc-FloDiff：直接使用真实位姿或预训练模型的预测结果
- 观测上下文 $c_t$、目标位置 $p_g$ 和智能体当前位姿 $(p_t, r_t)$ 的拼接结果随后输入策略网络以生成动作

一个基于 Transformer 的主干网络（用于融合视觉观测与楼层平面图）和一个设计用于场景内导航的策略网络

### 1. 观测上下文

- 观测图像

  每个观测图像使用 EfficientNet-B0 作为编码器 $\psi$，独立生成视觉潜在特征

- 环境的楼层平面图图像

  使用另一个 EfficientNet-B0 作为编码器 $\phi$ 处理楼层平面图图像

- 应用多头注意力层 $f(·)$ 融合两个分支的特征，最终输出特征作为观测上下文向量 $c_t$

### 2. 目标位置

根据标记的目标点 $g$ 计算世界坐标系中的目标位置 $p_g$

- 目标在楼层平面图图像上的像素坐标：$u_g$

- 通过 $p_g = u_g \cdot \mu + \delta$ 将坐标转换为世界坐标

### 3. 基于策略的 FloDiff 两种变体

#### Naive-FloDiff

引入全连接网络 $f_p$，从观测上下文向量 $c_t$ 中预测智能体位姿 $\hat{x}_t = (\hat{p}_t, \hat{r}_t)$

使用额外的全连接网络 $f_d$ 预测当前位置与目标的最短路径距离 $\hat{d}(t, g)$，避免策略直接朝向目标移动而陷入死胡同

将观测上下文向量 $c_t$、目标位置 $p_g$ 和预测位姿 $\hat{x}_t$ 拼接为条件向量，通过扩散策略 $\theta$ 对采样噪声去噪并生成动作序列

#### Loc-FloDiff

直接使用智能体的真实位姿或预训练模型的预测位姿，无需 Naive-FloDiff 中的 $f_p$ 网络

- Loc-FloDiff（GT）：使用真实位姿
- Loc-FloDiff（F3）：使用 F3Loc 预测位姿

#### 动作序列生成机制

时间步 $t$ 的预测动作序列 $A_t^0$ 表示未来 $H_p$ 步的动作序列，智能体仅执行前 $H_a$ 步

- 预测动作序列采样
- 通过 “当前位置叠加动作向量” 计算下一位置

### 4. 训练

- 从片段中随机采样固定时间跨度的轨迹段作为训练样本

  从完整片段中截取连续的 H 步作为一个训练样本

  - 减小计算开销
  - 数据增强
  - 覆盖不同场景，增强泛化能力

- 从采样轨迹后方随机选择目标位置 —— 增加目标的多样性

---

每组片段（episode）：

- 对不可导航区域进行膨胀处理
- 在可导航区域内随机选择两个相距至少 3 米的点作为起点和目标点
- 使用 A * 算法生成最短路径（像素坐标序列）
- 像素坐标转换为场景坐标系下的坐标，形成轨迹数据

> 具体实现的参数设置

## 实验与分析

### 1. 数据集

来自 Gibson 的 117 个静态室内场景

- 67 训练集
- 50 测试集，10 对起点终点，500 个测试对

每个场景

- 楼层平面图
  - 前人手动标注的版本
- 可导航地图
  - 从场景网格生成粗略地图
  - 手动优化以解决扫描伪影问题

楼层平面图未考虑家具障碍物，可能会发生碰撞

- 策略：当发生碰撞时，智能体将顺时针旋转 45° 并重新预测未来动作

### 2. 方法对比

- **Loc-A\*（F3）**：智能体使用预训练的 F3Loc 进行自我定位。随后，采用 A* 算法在楼层平面图上从预测位置到目标规划轨迹，并在环境中执行映射的动作
- **Loc-A\*（GT）**：将预测位姿替换为真实位姿
- **Naive-FloDiff**：在策略训练过程中直接学习预测智能体位姿
- **Loc-FloDiff（F3）**：基于 Loc-FloDiff 模型，使用与 Loc-A*（F3）相同的定位模块
- **Loc-FloDiff（GT）**：将预测位姿替换为真实位姿（GT）

> GT（Ground Truth），真实位姿，是为了剥离定位误差的影响，单独测试路径规划、决策算法的性能上限（控制变量法）

### 3. 评估指标

#### 1. 成功率

$$
SR = \frac{1}{N} \sum_{i=1}^{N} S_i
$$

- $N$：测试片段总数
- 若片段 $i$ 导航成功，则 $S_i = 1$，否则 $S_i = 0$

当导航任务满足以下条件时视为成功：

1. 智能体最终位置与目标的距离不超过指定阈值 $\tau_d$
2. 碰撞次数不超过给定阈值 $\tau_c$

#### 2. 路径长度加权成功率（SPL）

$$
SPL = \frac{1}{N} \sum_{i=1}^{N} S_i \cdot \frac{l_i}{\max(p_i, l_i)}
$$

- $p_i$：智能体实际路径长度
- $l_i$：起点到目标的最短路径长度

该指标用于衡量导航效率

### 4. 结果与讨论

#### 1. 结果

<img src="/img/FPN/FloNa/results.png" alt="results" style="zoom:50%;" />

#### 2. 分析

##### 1. 定位

- Naive-FloDiff 的成功率低于两个 Loc-FloDiff
  - 与端到端方法相比，将定位模块解耦的模块化方法在解决 FloNa 任务时更为有效
  - 编码器在同时编码用于定位和规划的信息时面临挑战

- F3 的表现逊于 GT
  - 在狭窄区域因与障碍物碰撞而被困（定位不准确）
    - 预训练数据差异（重新训练后，SR 和 SPL 确有提高，但效果仍一般）

##### 2. 避障

提高导航避障能力

- 定量
- 定性
  - 引入位姿噪声，看是否发生碰撞

##### 3. 规划

提高了在路径规划中的有效性和效率

- 定量
- 定性
  - 分配三个目标位置，生成的动作序列与目标颜色对应

##### 4. 鲁棒性

向输入位姿添加噪声会导致 SR 和 SPL 下降，但性能并未随噪声方差增加而持续恶化

##### 5. 楼层平面图

提供全局几何信息和障碍物分布，有效促进导航

#### 3. 实际场景部署

将策略部署在自动导引车（AGV）

采用基于单线激光雷达的里程计算法向智能体提供当前位姿
