---
layout:     post
title:      "F3Loc 论文研读"
subtitle:   "Fusion and Filtering for Floorplan Localization 论文研读"
date:       2025-06-22 18:00:00
author:     "hyy"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - FPN
---

论文提出了一种名为 F3Loc 的高效数据驱动室内定位方法，其基于**概率模型**，包含**观测模块**和**时间过滤模块**，通过单视图与多视图几何结合估计平面深度，并利用新颖的 SE2 直方图滤波器融合时序信息。该方法无需针对每个地图重新训练，可在消费级硬件上运行，克服了现有方法对直立图像的依赖，在召回率和定位速度上显著优于 State-of-the-Art 方法，且构建了包含 119 个室内环境的数据集并将公开。

- 模型基于一种新颖的**一维射线表示**，该表示反映了二维平面图的结构
- 从单视图和多视图线索中提取场景几何信息。一个新颖的**选择网络**根据当前相对位姿动态融合两者的输出，以充分利用两种方法的优势
- 一种使用**虚拟横滚俯仰**的数据增强技术克服了现有先进方法的局限性，使其能够在实际场景中处理非零横滚 / 俯仰角的情况
- 为了消除歧义并提升定位效果，预测结果通过一种新颖且高效的**直方图滤波器**进行时序融合，该滤波器利用自我运动构建为分组卷积形式
- 完整系统在现有基准测试中，无论是准确性还是效率都超越了先进方法，并且真实世界实验进一步证明了其在实际应用中的潜力
- 收集了一个大型室内数据集，该数据集由 119 个 Gibson 室内环境的平面图以及短时序和长时序观测组成，且将公开释放

## 部分名词解释

- SLAM（Simultaneous Localization and Mapping，同步定位与地图构建）

  是指机器人或移动设备在未知室内环境中运动时，实时构建环境地图并确定自身在地图中的位置的技术

  - 论文提出的 F3Loc 框架可以与室内 SLAM 互补

    因为 F3Loc 利用平面图1这一轻量化且长期稳定的环境表示，而室内 SLAM 通常依赖于传感器数据（如视觉、激光等）实时构建的环境模型，两者结合可以提高定位的准确性和鲁棒性

- SE2：二维空间中的**特殊欧几里得群**，用于表示平面内的**刚体运动**，包含**平移**和**旋转**两个自由度

  二维平面图中的坐标 $(s_x, s_y)$ 和朝向 $s_\phi$

- R2：**二维欧几里得空间**，仅包含**位置信息**，不考虑朝向

  坐标表示为 $(x, y)$，是 SE2 的子集（忽略旋转自由度）

- 观测模型：通过分析单帧或多帧 RGB 图像，估计相机与平面图中障碍物的距离（即**平面图深度**），并将其转换为可与平面图匹配的几何特征，从而计算当前位姿的可能性

- 深度估计：通过算法从图像中获取场景中物体与相机之间的距离

  - 单目深度估计：单张 RBG 图像特征与深度的映射关系（存在尺度歧义）
  - 多视图立体视觉（MVS）：利用同一场景的多张图像，通过特征匹配和几何约束计算像素深度

- 几何占用信息

  通过几何形状描述环境中障碍物的位置、轮廓及空间占据关系，不涉及物体的类别或功能属性，仅关注其对空间的物理阻挡作用

- 平面图深度

  相机到平面图中各几何占用边界的水平距离

- 多层感知机（MLP）

  结构简单，通用性强。通过多层神经元的非线性变换实现对复杂数据的建模，广泛应用于分类、回归、特征提取等任务

- MVS（Multi-View Stereo，多视图立体视觉） 

  通过多个不同视角的图像恢复场景的三维结构

- 直方图滤波器

  一种用于状态估计的概率滤波方法，通过贝叶斯迭代，核心思想是通过离散化状态空间并利用直方图形式表示后验概率分布，从而实现对动态系统状态的跟踪与预测

- 重力对齐处理

  将相机拍摄的图像转换为“重力方向垂直向下”的标准姿态

  - 当相机倾斜拍摄时，图像中的地面可能是倾斜的，通过旋转将地面“校正”为水平，使重力方向与图像垂直轴对齐
  - 通过旋转矩阵 $\mathbf{R}$ 将原始相机坐标系下的点转换到“重力对齐”坐标系
  - 对齐后，利用单应性变换映射

- L1 损失：平均绝对误差

  衡量预测值与真实值的差异。本质是计算两者差值的绝对值的平均值，对异常值的鲁棒性较强

  | 损失函数       | 数学形式                                   | 特点                                                   | 适用场景                             |
  | -------------- | ------------------------------------------ | ------------------------------------------------------ | ------------------------------------ |
  | **L1 损失**    | $\| \hat{y} - y \|$                      | 梯度恒定，对异常值不敏感（鲁棒性强），但在零点处不可导 | 深度估计、图像去噪等需要鲁棒性的任务 |
  | **L2 损失**    | $(\hat{y} - y)^2$                          | 梯度随误差增大而增大，对异常值敏感，但光滑可导         | 回归任务（如房价预测）               |
  | **Huber 损失** | $\begin{cases} \frac{1}{2}x^2 & \text{if } \| x                                                      \| \leq \delta \\ \delta (              \| x \| - \frac{1}{2}\delta) & \text{otherwise} \end{cases}$ | 结合 L1 和 L2 优点，小误差时类似 L2，大误差时类似 L1，平滑可导 | 目标检测、自动驾驶等存在异常值的场景 |


## 现有的问题

- 平面图中存在大量几何相似的结构，这些结构会导致不同位置的视觉观测具有高度相似性

  - 仅依据单帧图像匹配平面图时，无法区分这些相似结构对应的真实位置，从而产生 “定位歧义”

  图像序列包含连续多帧的视觉信息和相机运动轨迹，能提供单帧缺失的上下文线索

  - 运动一致性：排除与运动轨迹不匹配的歧义位置
  - 多视角融合：重复结构在多视角下的几何关系会呈现差异

- 单帧定位：仅利用单张 RGB 图像与平面图匹配，直接估计相机在平面图中的位姿（坐标与朝向）的技术

  为融入时序滤波框架，单帧定位需同时满足“高精度”和“高效率”

  - 高精度：防止单帧误差在时序传递中累积，确保后验概率收敛到真实位姿
  - 高效率：维持滤波频率与相机运动同步，避免因观测延迟导致定位滞后

- 直立相机位姿：相机的**滚动角和俯仰角均为零**，即相机光轴严格垂直于地面，镜头朝向水平方向，不存在倾斜

  - **硬件依赖**：要求设备必须保持直立姿态，自然不支持自然拍摄情景
  - **场景限制**：无法处理需要相机倾斜拍摄的环境，通用性⬇

- 只考虑全景图像：覆盖水平 360° 或垂直 180° 视角的图像（如通过鱼眼镜头或多图像拼接生成）

  普通单目透视图像：如手机拍摄的单帧照片

  - **设备门槛高**：全景图像需要特殊硬件或复杂拼接算法
  - **实时性差**：全景图像数据量庞大，处理速度慢

## 研究现状

- 基于图像检索的方法
- 基于预构建的环境三维运动恢复结构模型的方法
- 数据驱动模型
  - 场景坐标回归（3D）
  - 位姿回归
- 激光雷达的使用限制
- 基于学习的方法仅使用 RGB 图像在平面图中进行定位
  - LaLaLoc：全景图像，假设已知相机和天花板高度
  - LaLaLoc++：将整个平面图直接嵌入特征空间，消除高度的假设
  - Laser：平面图表示为一组点
- PF-net：其观测模型通过学习图像与对应的前向地图块之间的相似度构建

## 方法

整体流程

![overview](/img/FPN/F3Loc/overview.png)

- 从当前帧和已知相对位姿的最近几帧中估计平面图深度
- 多层感知机基于相对位姿及其各自的平均深度预测来融合这两种估计
- 直方图滤波器进行时序集成

### 1. 单图像定位

- 将图像与重力方向对齐，特征网络预测平面图深度

  <img src="/img/FPN/F3Loc/network-depth.png" alt="network-depth" style="zoom: 50%;" />

- 从预测的平面图深度插值得到等角射线，通过在平面图中寻找与预测射线最相似的位姿实现定位

  <img src="/img/FPN/F3Loc/ray.png" alt="ray" style="zoom:50%;" />

### 2. 多视图立体估计

<img src="/img/FPN/F3Loc/MVS.png" alt="MVS" style="zoom:50%;" />

采用一种 MVS 网络变体，从已知相对位姿的多帧图像中估计平面图深度

- 网络提取图像各列的特征，并在注意力模块中应用重力对齐掩码

- 垂直压缩了深度预测和特征提取过程，无需为每个像素预测深度或提取特征

- 跨视图特征方差在深度假设上形成代价分布，生成二维代价分布
  $$
  d = d_{\text{hyp}}^{\top} \text{softmax}(-c)
  $$

  - $d_{\text{hyp}}$：包含 $D$ 个深度假设的向量
  - $c$：每个假设对应的代价
  - softmax(−c)：每个假设的概率

### 3. 学习互补选择

- 单目深度估计与相机运动无关，但易受尺度模糊影响
- 多视图立体匹配方法可得到正确尺度，却依赖足够的基线长度和相机重叠度 

采用另一个多层感知机（MLP）来从两种预测中进行软性选择，输出两种估计的权重，将概率分布按加权平均的方式融合
$$
P_{\text{fuse}} = w \cdot \text{Upsample}(P_{\text{mono}}) + (1 - w) \cdot P_{\text{mv}}
$$

- $0 \leq w \leq 1$ 由多层感知机输出
- $P_{\text{mono}}$ 表示单视图的概率分布
- $P_{\text{mv}}$ 表示多视图的概率分布

融合后的概率分布 $P_{\text{fuse}}$ 的期望即为最终的深度预测结果

### 4. 序列定位

使用直方图滤波器来跟踪整个平面图上的后验分布

- 建立观测模型
- 帧间相对位姿作为转移模型
- 转移概率
- 将平移和旋转解耦，对不同朝向应用不同的二维平移滤波器，然后沿朝向轴对整个概率体应用旋转滤波器

<img src="/img/FPN/F3Loc/filter-1.png" alt="filter-1" style="zoom:50%;" />

自运动样本推导的平移滤波器和旋转滤波器示意图

<img src="/img/FPN/F3Loc/filter-2.png" alt="filter-2" style="zoom:50%;" />

转移过程：概率体被划分为朝向数量个分组，每个分组与对应的平移滤波器卷积后重新堆叠。沿朝向轴进行循环填充后，概率体与旋转滤波器卷积以完成转移步骤

## 训练

针对真实平面图优化 L1 损失，单目网络除外额外添加通过余弦相似度计算的形状损失

### 数据集

创建了一个数据集：118 个不同的室内环境

- 包含原地旋转的 - 一般运动：Gibson (g)
- 不含原地旋转的 - 向前运动：Gibson (f)
- 轨迹分析：Gibson (t)

在 Structured3D 上评估了所提出的单帧定位方法

### 虚拟横滚俯仰增强

模拟不同姿态 → 重力对齐 → 屏蔽不可观测像素 → 生成训练数据

应对非直立相机位姿

- **训练阶段**中通过算法模拟相机在不同横滚 / 俯仰角度下的成像效果
- 数据增强
- 让模型学习到对各种非直立相机姿态的适应性

相机在不同姿态下拍摄的图像，可通过单应性变换关联

通过模拟不同的横滚角和俯仰角，计算哪些像素在新姿态下可观测，并屏蔽不可观测的像素

增强后，模型通过学习大量虚拟姿态数据，对非直立相机位姿的鲁棒性显著提升

## 实验结果

基线：PF-net 和 LASER

### 1. 观测模型

- 精确的平面图深度估计

- 一维射线扫描表示具有旋转和平移不变性，并且天然考虑了遮挡情况

#### 单帧评估

显著提高了召回率：模型成功定位到真实位置的比例（预测位置与真实位置的距离误差小于阈值）

对朝向估计的稳定性

> 机器人导航场景中对召回率要求较高，对精确率无明显关注（推测模型也不会针对一次预测生成大量候选位置）

#### 多视图评估

召回率显著提高

在观测模型中使用多视图几何线索进行平面图深度估计是有效的

多视图会受到普通运动数据集（如 Gibson (g)）中存在的短基线或重叠不足的影响，导致召回率均低于单目模块

#### 选择网络评估

单目与多视图估计优势互补 + 复杂的选择规则

<img src="/img/FPN/F3Loc/select-network.png" alt="select-network" style="zoom:50%;" />

选择权重与相对位姿的关系，计算单目和多视图观测估计的加权组合

相对位姿的退化程度越高，越倾向于选择单目估计

#### 虚拟横滚俯仰增强

<img src="/img/FPN/F3Loc/trend-chart.png" alt="trend-chart" style="zoom:50%;" />

- 未使用增强训练的网络在受到横滚俯仰干扰时，召回率呈现下降趋势
- 相比之下，虚拟横滚俯仰增强显著提升了模型在非直立相机位姿下的召回率鲁棒性

### 2. 序列定位

<img src="/img/FPN/F3Loc/sequence-positioning.png" alt="sequence-positioning" style="zoom:33%;" />

直方图滤波器能够有效维持相机位姿的全局后验分布（收敛）

- 在起始阶段，分布存在多个模态
- 随着相机移动提供越来越多的证据，该分布会收敛到单一的尖锐峰值

成功率：使用更多帧数会提高成功率

运行时间：

- 特征提取上略有减慢
- 快速匹配
- 最高的迭代速率
- 直方图滤波迭代速度比粒子滤波快

## 真实场景实验

定制 LaMAR 数据集（一个包含三个场景的真实数据集）

- 运动模糊、非朗伯表面、歧义性和遮挡
- 系统从第二步开始跟踪相机位姿，并在此后紧密贴合真实轨迹
- 尽管场景规模较大，直方图滤波器仍保持高效，定位频率达 3 赫兹

## 结论与展望

数据驱动的概率模型，用于平面图内的定位任务

精确的单帧定位和序列定位，更具实用性，仅需消费级硬件、透视 RGB 图像和非直立相机位姿，同时支持极高帧率的运行

- 更多真实场景数据集以缩小领域差距
- 通过结合图像和平面图中的语义信息，可进一步减少歧义性